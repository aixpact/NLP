{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam analysis and classification\n",
    "Explore text message data and create models to predict if a message is spam or not. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "You are currently looking at **version 1.0** of this notebook.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from scipy.sparse import csr_matrix, hstack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_data = pd.read_csv('spam.csv')\n",
    "spam_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_data['target'] = np.where(spam_data['target']=='spam', 1, 0)\n",
    "spam_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(spam_data['text'], spam_data['target'], random_state=0)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percentage of spam in the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_data['target'].mean()*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer\n",
    "Fit the training data `X_train` using a Count Vectorizer with default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer().fit(X_train)\n",
    "names = sorted(vect.get_feature_names(), key=lambda x:len(x), reverse=True)\n",
    "names[:5], len(names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes classifier\n",
    "Fit and transform the training data `X_train` using a Count Vectorizer with default parameters.  \n",
    "Next, fit a multinomial Naive Bayes classifier model with smoothing `alpha=0.1`.   \n",
    "Find the area under the curve (AUC) score using the transformed test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer().fit(X_train)\n",
    "X_train_vectorized = vect.transform(X_train)\n",
    "X_test_vectorized = vect.transform(X_test)\n",
    "len(vect.get_feature_names()), X_test_vectorized.shape, print(str(X_train_vectorized[0])), X_train[0], y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = MultinomialNB(alpha=0.1).fit(X_train_vectorized, y_train)\n",
    "y_predict = nb.predict(X_test_vectorized)\n",
    "roc_auc_score(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tf-idf Vectorizer\n",
    "Equivalent to CountVectorizer followed by TfidfTransformer:\n",
    " - Transform a count matrix to a normalized tf or tf-idf representation\n",
    "\n",
    "Tf means term-frequency while tf-idf means term-frequency times inverse document-frequency.  \n",
    "This is a common term weighting scheme in information retrieval, that has also found good use in document classification.\n",
    "\n",
    "The goal of using tf-idf instead of the raw frequencies of occurrence of a token in a given document is to **scale down the impact of tokens that occur very frequently in a given corpus** and that are hence empirically less informative than features that occur in a small fraction of the training corpus.\n",
    "\n",
    " - Fit and transform the training data `X_train` using a Tfidf Vectorizer with default parameters.\n",
    " - Get 20 features with smallest tf-idf and the largest tf-idf\n",
    " - Put these features in a two series where each series is sorted by tf-idf value and then alphabetically by feature name. \n",
    " - The index of the series should be the feature name, and the data should be the tf-idf.\n",
    " - The series of 10 features with smallest tf-idfs should be sorted smallest tfidf first, \n",
    " - the list of 10 features with largest tf-idfs should be sorted largest first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer().fit(X_train)\n",
    "X_train_vectorized = vect.transform(X_train)\n",
    "tfidf_values = X_train_vectorized.max(0).toarray()[0]\n",
    "feature_names = np.array(vect.get_feature_names())\n",
    "print(X_train_vectorized.max(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10\n",
    "df = pd.DataFrame([feature_names, tfidf_values], index=['feature', 'tf-idf']).T\n",
    "smallest_tfidfs = df.sort_values(by=['tf-idf', 'feature'], ascending=[1, 1]).set_index('feature').head(N)\n",
    "largest_tfidfs = df.sort_values(by=['tf-idf', 'feature'], ascending=[0, 1]).set_index('feature').head(N)\n",
    "smallest_tfidfs, '\\n', largest_tfidfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultinomialNB \n",
    "with Tfidf Vectorizer ignoring terms that have a document frequency strictly lower than **N**\n",
    " - fit a multinomial Naive Bayes classifier model with smoothing `alpha=0.1`\n",
    " - compute the area under the curve (AUC) score using the transformed test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 3\n",
    "vect = TfidfVectorizer(min_df=N).fit(X_train)\n",
    "X_train_vectorized = vect.transform(X_train)\n",
    "X_test_vectorized = vect.transform(X_test)\n",
    "\n",
    "nb = MultinomialNB(alpha=0.1).fit(X_train_vectorized, y_train)\n",
    "y_predict = nb.predict(X_test_vectorized)\n",
    "roc_auc_score(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average length of documents (# of chars) for ham and spam documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_index = spam_data['target'] == 1\n",
    "spam_data['length'] = [len(x) for x in spam_data['text']]\n",
    "spam_data.loc[spam_index, 'length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_data.loc[~spam_index, 'length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_data.loc[~spam_index, 'length'].describe() / spam_data.loc[spam_index, 'length'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add feature function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_feature(X, feature_to_add):\n",
    "    \"\"\"\n",
    "    Returns sparse feature matrix with added feature.\n",
    "    feature_to_add can also be a list of features.\n",
    "    csr = scipy Compressed Sparse Row matrix\n",
    "    \"\"\"\n",
    "    return hstack([X, csr_matrix(feature_to_add).T], 'csr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC \n",
    "with Tfidf Vectorizer ignoring terms that have a document frequency strictly lower than **N**.\n",
    " - add an additional feature, **the length of document (number of characters)** to the document-term matrix \n",
    " - fit a Support Vector Classification model with regularization `C=10000`\n",
    " - compute the area under the curve (AUC) score using the transformed test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 5\n",
    "vect = TfidfVectorizer(min_df=N).fit(X_train)\n",
    "X_train_vectorized = vect.transform(X_train)\n",
    "X_test_vectorized = vect.transform(X_test)\n",
    "\n",
    "doc_len_train = [len(x) for x in X_train]\n",
    "doc_len_test = [len(x) for x in X_test]\n",
    "\n",
    "X_train_vectorized = add_feature(X_train_vectorized, doc_len_train)\n",
    "X_test_vectorized = add_feature(X_test_vectorized, doc_len_test)\n",
    "\n",
    "fit = SVC(C=10000).fit(X_train_vectorized, y_train)\n",
    "y_pred = fit.predict(X_test_vectorized)\n",
    "roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average number of Digits per document for ham and spam documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_index = spam_data['target'] == 1\n",
    "spam_data['digits'] = [len(''.join(re.findall('\\d+', x))) for x in spam_data['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_data.loc[~spam_index, 'digits'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_data.loc[spam_index, 'digits'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression model with regularization\n",
    "- fit and transform the training data `X_train` using a Tfidf Vectorizer ignoring terms that have a document frequency strictly lower than **5**\n",
    "- using **word n-grams from n=1 to n=3** (unigrams, bigrams, and trigrams).\n",
    "\n",
    "Using this document-term matrix and the following additional features:\n",
    "* the length of document (number of characters)\n",
    "* **number of digits per document**\n",
    "\n",
    "\n",
    "1. fit a Logistic Regression model with regularization `C=100`\n",
    "2. compute the area under the curve (AUC) score using the transformed test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 5\n",
    "vect = TfidfVectorizer(min_df=N, ngram_range=(1, 3)).fit(X_train)\n",
    "X_train_vectorized = vect.transform(X_train)\n",
    "X_test_vectorized = vect.transform(X_test)\n",
    "\n",
    "# add feature: # of chars\n",
    "doc_len_train = [len(x) for x in X_train]\n",
    "doc_len_test = [len(x) for x in X_test]\n",
    "\n",
    "X_train_vectorized = add_feature(X_train_vectorized, doc_len_train)\n",
    "X_test_vectorized = add_feature(X_test_vectorized, doc_len_test)\n",
    "\n",
    "# add feature: # of digits\n",
    "dig_len_train = [len(''.join(re.findall('\\d+', x))) for x in X_train]\n",
    "dig_len_test = [len(''.join(re.findall('\\d+', x))) for x in X_test]\n",
    "\n",
    "X_train_vectorized = add_feature(X_train_vectorized, dig_len_train)\n",
    "X_test_vectorized = add_feature(X_test_vectorized, dig_len_test)\n",
    "\n",
    "# fit & predict model\n",
    "lr = LogisticRegression(C=100).fit(X_train_vectorized, y_train)\n",
    "y_pred = lr.predict(X_test_vectorized)\n",
    "roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average # of non-word characters \n",
    "anything other than a letter, digit or underscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_index = spam_data['target'] == 1\n",
    "spam_data['len_'] = [len(''.join(re.findall('\\W+', x))) for x in spam_data['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_data.loc[~spam_index, 'len_'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_data.loc[spam_index, 'len_'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression model with regularization\n",
    "\n",
    "Fit and transform the training data X_train using a Count Vectorizer \n",
    " - ignoring terms that have a document frequency strictly lower than **5** \n",
    " - using **character n-grams from n=2 to n=5.**\n",
    " - use character n-grams pass in `analyzer='char_wb'` = more robust to spelling mistakes\n",
    "\n",
    "Using this document-term matrix and the following additional features:\n",
    "* the length of document (number of characters)\n",
    "* number of digits per document\n",
    "* number of non-word characters\n",
    "['length_of_doc', 'digit_count', 'non_word_char_count']\n",
    "\n",
    "\n",
    "1. fit a Logistic Regression model with regularization C=100. \n",
    "2. compute the area under the curve (AUC) score using the transformed test data.\n",
    "3. find the 10 smallest and 10 largest coefficients from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_add = ['length_of_doc', 'digit_count', 'non_word_char_count']\n",
    "\n",
    "vect = CountVectorizer(min_df=6, ngram_range=(2, 5), analyzer='char_wb').fit(X_train)\n",
    "X_train_vectorized = vect.transform(X_train)\n",
    "X_test_vectorized = vect.transform(X_test)\n",
    "\n",
    "# Train\n",
    "ftrs = pd.DataFrame([(len(x), \n",
    "                      len(''.join(re.findall('\\d+', x))), \n",
    "                      len(''.join(re.findall('\\W+', x)))) \n",
    "                      for x in X_train], columns=features_to_add)\n",
    "\n",
    "X_train_vectorized = add_feature(X_train_vectorized, [ftrs.loc[:, 'length_of_doc'],\n",
    "                                                      ftrs.loc[:, 'digit_count'], \n",
    "                                                      ftrs.loc[:, 'non_word_char_count']])\n",
    "\n",
    "# Test\n",
    "ftrs = pd.DataFrame([(len(x), \n",
    "                      len(''.join(re.findall('\\d+', x))), \n",
    "                      len(''.join(re.findall('\\W+', x)))) \n",
    "                      for x in X_test], columns=features_to_add)\n",
    "\n",
    "X_test_vectorized = add_feature(X_test_vectorized, [ftrs.loc[:, 'length_of_doc'],\n",
    "                                                    ftrs.loc[:, 'digit_count'], \n",
    "                                                    ftrs.loc[:, 'non_word_char_count']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit \n",
    "lr = LogisticRegression(C=100).fit(X_train_vectorized, y_train)\n",
    "y_predict = lr.predict(X_test_vectorized)\n",
    "roc_auc_score(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = vect.get_feature_names() + ['length_of_doc', 'digit_count', 'non_word_char_count']\n",
    "df = pd.DataFrame([lr.coef_[0].argsort(), features]).T.set_index(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[sorted_coef_index[:10],]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[sorted_coef_index[:-11:-1],]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
